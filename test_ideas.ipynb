{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Everybody', 'read', 'that', 'book']\n"
     ]
    }
   ],
   "source": [
    "print(\"Everybody read that book\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fad48611390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1) # random num generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      " -2.0339  1.0273  0.1824\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      "\n",
      "Variable containing:\n",
      "-0.1315\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "(Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.1315  0.0005 -0.0497\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      ", Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.3820  0.0008 -0.3134\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      ")\n",
      "next step\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.8898  1.6604  0.6113\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.7922\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "(Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.0018 -0.1380 -0.0150\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      ", Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.0033 -0.1918 -0.0728\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      ")\n",
      "next step\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.8490 -1.4300  0.3975\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      "\n",
      "Variable containing:\n",
      "-0.1476\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "(Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.1476  0.0261 -0.1521\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      ", Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.2142  0.0394 -0.2352\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      ")\n",
      "next step\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  1.0469 -0.3277  0.2539\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      "\n",
      "Variable containing:\n",
      "-0.1765\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "(Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.1765 -0.0243 -0.1447\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      ", Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.3500 -0.0343 -0.2706\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      ")\n",
      "next step\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.2067  0.6352  0.3487\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -6.4637\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "(Variable containing:\n",
      "(0 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  -6.4637 -6.4860 -7.3651\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      ", Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.1185 -0.0927 -0.2062\n",
      "[torch.FloatTensor of size 1x1x3]\n",
      ")\n",
      "next step\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "\n",
    "# make a random sequence of length 5, dim_feat 3\n",
    "inputs = [autograd.Variable(torch.randn((1, 3)))\n",
    "          for _ in range(5)] \n",
    "\n",
    "# initialize the hidden state. \n",
    "hidden = (autograd.Variable(torch.randn(1, 1, 3)),\n",
    "          autograd.Variable(torch.randn((1, 1, 3))))\n",
    "\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # lstm input must be 3d tensor, so generate a fake one 1x1x3 with view\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    print(i.view(1, 1, -1))\n",
    "    print(out)\n",
    "    print(hidden)\n",
    "    print('next step')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.arange(15).reshape(3, 5)\n",
    "b = np.array([[6, 7, 8],a \n",
    "              [3, 4, 5]])\n",
    "c = np.array( [ [1,2], [3,4] ], dtype=complex )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('complex128')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19722887  0.38423995  0.19222589]\n",
      " [ 0.02360551  0.38484693  0.25716588]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.77369471,  0.66561832])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.random.random((2,3))\n",
    "print(d)\n",
    "d.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1000, -1000, -1000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([  0,   1,   8,  27,  64, 125, 216, 343, 512, 729])\n",
    "a[0:6:2] = -1000    # equivalent to a[0:6:2] = -1000; from start to position 6, exclusive, set every 2nd element to -1000\n",
    "a[0:6:2] # for(index = 0; index <6; index += 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  2,  0,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(15)\n",
    "a[[0,1,3]] = [0, 0, 0] \n",
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
